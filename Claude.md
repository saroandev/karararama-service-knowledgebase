# RAG Pipeline - Mimari DokÃ¼mantasyon

## ğŸ¯ Proje Ã–zeti

Bu proje, PDF dosyalarÄ±ndan bilgi Ã§Ä±kararak kullanÄ±cÄ±larÄ±n doÄŸal dilde sorduklarÄ± sorulara kaynak gÃ¶stererek cevap veren bir **Retrieval-Augmented Generation (RAG)** sistemidir. Sistem tamamen Docker Ã¼zerinde Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r ve mikroservis mimarisine sahiptir.

### Temel Ã–zellikler
- ğŸ“„ PDF dosyalarÄ±nÄ±n otomatik iÅŸlenmesi ve indekslenmesi
- ğŸ” Semantik arama ile ilgili iÃ§eriÄŸin bulunmasÄ±
- ğŸ’¬ Kaynak gÃ¶stererek doÄŸal dilde cevap Ã¼retimi
- ğŸš€ YÃ¼ksek performanslÄ± vektÃ¶r aramasÄ± (Milvus)
- ğŸ“¦ Ã–lÃ§eklenebilir object storage (MinIO)
- ğŸ”§ RESTful API ve WebSocket desteÄŸi

## ğŸ—ï¸ Sistem Mimarisi

### Teknoloji Stack'i

| BileÅŸen | Teknoloji | AmaÃ§ |
|---------|-----------|------|
| Object Storage | MinIO | PDF ve chunk dosyalarÄ±nÄ±n saklanmasÄ± |
| Vector Database | Milvus | Embedding vektÃ¶rlerinin saklanmasÄ± ve aranmasÄ± |
| Metadata Store | ETCD | Milvus metadata yÃ¶netimi |
| PDF Parser | PyMuPDF | PDF dosyalarÄ±ndan metin Ã§Ä±karma |
| Text Splitter | LangChain | Metni anlamlÄ± parÃ§alara bÃ¶lme |
| Embedding Model | BGE-M3 | Metin â†’ vektÃ¶r dÃ¶nÃ¼ÅŸÃ¼mÃ¼ |
| Reranker | BGE-Reranker-v2-m3 | Arama sonuÃ§larÄ±nÄ± yeniden sÄ±ralama |
| LLM | OpenAI/Ollama | Cevap Ã¼retimi |
| Backend | FastAPI | REST API servisi |
| Containerization | Docker | TÃ¼m servislerin orkestrayonu |

### Mimari Diyagram

```mermaid
graph TB
    subgraph "Client Layer"
        UI[Web UI/API Client]
    end
    
    subgraph "API Layer"
        API[FastAPI Server]
        WS[WebSocket Handler]
    end
    
    subgraph "Processing Layer"
        INGEST[Ingest Pipeline]
        PARSE[PDF Parser]
        CHUNK[Text Chunker]
        EMBED[Embedding Generator]
        RETRIEVE[Retriever]
        GENERATE[LLM Generator]
    end
    
    subgraph "Storage Layer"
        MINIO[MinIO<br/>Object Storage]
        MILVUS[Milvus<br/>Vector DB]
        ETCD[ETCD<br/>Metadata]
    end
    
    UI --> API
    UI -.->|real-time updates| WS
    API --> INGEST
    API --> RETRIEVE
    RETRIEVE --> GENERATE
    
    INGEST --> PARSE
    PARSE --> CHUNK
    CHUNK --> EMBED
    EMBED --> MILVUS
    
    PARSE --> MINIO
    CHUNK --> MINIO
    
    MILVUS --> ETCD
    RETRIEVE --> MILVUS
    RETRIEVE --> MINIO
```

## ğŸ“Š Veri AkÄ±ÅŸ DiyagramÄ±

### 1. PDF Ä°ndeksleme AkÄ±ÅŸÄ± (Ingest)

```
PDF DosyasÄ± 
    â†“
[1. Upload] â†’ MinIO (raw-pdfs bucket)
    â†“
[2. Parse] â†’ Metin Ã§Ä±karma + metadata
    â†“
[3. Chunk] â†’ Token bazlÄ± bÃ¶lme (512 token, 50 overlap)
    â†“
[4. Embed] â†’ BGE-M3 ile vektÃ¶r Ã¼retimi (1024 dimension)
    â†“
[5. Index] â†’ Milvus'a vektÃ¶r + metadata kayÄ±t
    â†“
[6. Store] â†’ MinIO'ya chunk metinleri kayÄ±t (chunks bucket)
```

### 2. Soru-Cevap AkÄ±ÅŸÄ± (Query)

```
KullanÄ±cÄ± Sorusu
    â†“
[1. Embed] â†’ Soru vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r
    â†“
[2. Search] â†’ Milvus'ta en yakÄ±n K=10 chunk bulunur
    â†“
[3. Rerank] â†’ BGE-Reranker ile yeniden sÄ±ralama (top 5)
    â†“
[4. Retrieve] â†’ MinIO'dan chunk metinleri Ã§ekilir
    â†“
[5. Context] â†’ Prompt hazÄ±rlanÄ±r (soru + context + instructions)
    â†“
[6. Generate] â†’ LLM ile cevap Ã¼retimi
    â†“
[7. Response] â†’ JSON formatÄ±nda kaynaklÄ± cevap
```

## ğŸ“ Proje Dosya YapÄ±sÄ±

```
onedocs-rag/
â”œâ”€â”€ docker-compose.yml          # Docker servisleri orkestrasyonu
â”œâ”€â”€ Dockerfile                  # FastAPI uygulamasÄ± iÃ§in container
â”œâ”€â”€ .env                       # Ortam deÄŸiÅŸkenleri (gitignore)
â”œâ”€â”€ .env.example              # Ortam deÄŸiÅŸkenleri ÅŸablonu
â”œâ”€â”€ requirements.txt          # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ Claude.md                # Bu dokÃ¼mantasyon
â”‚
â”œâ”€â”€ app/                     # Ana uygulama kodu
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py           # KonfigÃ¼rasyon yÃ¶netimi
â”‚   â”œâ”€â”€ storage.py          # MinIO iÅŸlemleri
â”‚   â”œâ”€â”€ parse.py            # PDF parsing fonksiyonlarÄ±
â”‚   â”œâ”€â”€ chunk.py            # Metin bÃ¶lme fonksiyonlarÄ±
â”‚   â”œâ”€â”€ embed.py            # Embedding Ã¼retimi
â”‚   â”œâ”€â”€ index.py            # Milvus indeksleme
â”‚   â”œâ”€â”€ retrieve.py         # VektÃ¶r arama ve retrieval
â”‚   â”œâ”€â”€ generate.py         # LLM cevap Ã¼retimi
â”‚   â”œâ”€â”€ ingest.py           # Ä°ndeksleme pipeline orkestrasyonu
â”‚   â””â”€â”€ server.py           # FastAPI endpoints
â”‚
â”œâ”€â”€ data/                   # Local veri dizinleri (Docker volumes)
â”‚   â”œâ”€â”€ minio/             # MinIO storage
â”‚   â”œâ”€â”€ milvus/            # Milvus vektÃ¶r veritabanÄ±
â”‚   â””â”€â”€ etcd/              # ETCD metadata
â”‚
â”œâ”€â”€ tests/                 # Test dosyalarÄ±
â”‚   â”œâ”€â”€ test_parse.py
â”‚   â”œâ”€â”€ test_chunk.py
â”‚   â”œâ”€â”€ test_embed.py
â”‚   â””â”€â”€ test_api.py
â”‚
â””â”€â”€ scripts/              # YardÄ±mcÄ± scriptler
    â”œâ”€â”€ setup.sh         # Ä°lk kurulum scripti
    â”œâ”€â”€ seed_data.py     # Ã–rnek veri yÃ¼kleme
    â””â”€â”€ cleanup.sh       # Temizlik scripti
```

## ğŸ³ Docker Container Mimarisi

### Container'lar ve Ä°liÅŸkileri

```yaml
Services:
  1. minio (minio/minio:latest)
     - Port: 9000 (API), 9001 (Console)
     - Volume: ./data/minio:/data
     - Buckets: raw-pdfs, chunks
  
  2. etcd (quay.io/coreos/etcd:latest)
     - Port: 2379, 2380
     - Volume: ./data/etcd:/etcd-data
  
  3. milvus (milvusdb/milvus:latest)
     - Port: 19530 (gRPC), 9091 (metrics)
     - Volume: ./data/milvus:/var/lib/milvus
     - Depends on: etcd, minio
  
  4. attu (zilliz/attu:latest)
     - Port: 8000
     - Milvus GUI yÃ¶netim arayÃ¼zÃ¼
  
  5. app (custom FastAPI)
     - Port: 8080
     - Environment: Production
     - Depends on: minio, milvus
```

### Docker Network YapÄ±sÄ±

```
rag-network (bridge)
    â”œâ”€â”€ minio:9000
    â”œâ”€â”€ etcd:2379
    â”œâ”€â”€ milvus:19530
    â”œâ”€â”€ attu:8000
    â””â”€â”€ app:8080
```

## ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

### Gereksinimler
- Docker & Docker Compose (v2.0+)
- Python 3.9+ (local development iÃ§in)
- 8GB+ RAM (Ã¶nerilen 16GB)
- 20GB+ boÅŸ disk alanÄ±

### AdÄ±m 1: Repository'yi Klonlama

```bash
git clone https://github.com/yourusername/onedocs-rag.git
cd onedocs-rag
```

### AdÄ±m 2: Ortam DeÄŸiÅŸkenlerini Ayarlama

```bash
cp .env.example .env
# .env dosyasÄ±nÄ± dÃ¼zenleyin ve API key'leri ekleyin
```

### AdÄ±m 3: Docker Container'larÄ± BaÅŸlatma

```bash
# TÃ¼m servisleri baÅŸlat
docker-compose up -d

# Log'larÄ± takip et
docker-compose logs -f

# Servis durumlarÄ±nÄ± kontrol et
docker-compose ps
```

### AdÄ±m 4: Servislerin HazÄ±r OlmasÄ±nÄ± Bekleme

```bash
# Health check (yaklaÅŸÄ±k 30-60 saniye)
curl http://localhost:8080/health
```

### AdÄ±m 5: Ä°lk PDF'i YÃ¼kleme

```bash
# PDF indeksleme
curl -X POST "http://localhost:8080/ingest" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@sample.pdf" \
  -F "metadata={\"source\":\"manual\",\"tags\":[\"test\"]}"
```

### AdÄ±m 6: Soru Sorma

```bash
# Query endpoint
curl -X POST "http://localhost:8080/query" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Bu dokÃ¼manda ne anlatÄ±lÄ±yor?",
    "top_k": 5,
    "use_reranker": true
  }'
```

## ğŸ“¡ API Endpoints

### 1. PDF Ä°ndeksleme

```http
POST /ingest
Content-Type: multipart/form-data

Parameters:
  - file: PDF dosyasÄ± (required)
  - metadata: JSON metadata (optional)
  - chunk_size: Token sayÄ±sÄ± (default: 512)
  - chunk_overlap: Overlap token sayÄ±sÄ± (default: 50)

Response:
{
  "status": "success",
  "document_id": "doc_123456",
  "chunks_created": 42,
  "processing_time": 3.14
}
```

### 2. Soru-Cevap

```http
POST /query
Content-Type: application/json

Body:
{
  "question": "string",
  "top_k": 5,
  "use_reranker": true,
  "filters": {
    "document_id": "doc_123456",
    "date_range": ["2024-01-01", "2024-12-31"]
  }
}

Response:
{
  "answer": "string",
  "sources": [
    {
      "chunk_id": "chunk_789",
      "document_id": "doc_123456",
      "page": 3,
      "score": 0.92,
      "text": "relevant chunk text..."
    }
  ],
  "metadata": {
    "model": "gpt-4",
    "processing_time": 1.23,
    "tokens_used": 450
  }
}
```

### 3. DokÃ¼man Listeleme

```http
GET /documents
Query Parameters:
  - page: int (default: 1)
  - limit: int (default: 20)
  - sort: string (date|name|size)

Response:
{
  "documents": [...],
  "total": 100,
  "page": 1,
  "pages": 5
}
```

### 4. DokÃ¼man Silme

```http
DELETE /documents/{document_id}

Response:
{
  "status": "success",
  "deleted_chunks": 42
}
```

### 5. Health Check

```http
GET /health

Response:
{
  "status": "healthy",
  "services": {
    "minio": "connected",
    "milvus": "connected",
    "embedding_model": "loaded"
  },
  "version": "1.0.0"
}
```

### 6. WebSocket - GerÃ§ek ZamanlÄ± Ä°ÅŸlem Takibi

```javascript
// WebSocket baÄŸlantÄ±sÄ±
const ws = new WebSocket('ws://localhost:8080/ws');

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Progress:', data);
  // {
  //   "type": "progress",
  //   "stage": "parsing",
  //   "progress": 45,
  //   "message": "Processing page 12 of 30"
  // }
};
```

## ğŸ”§ KonfigÃ¼rasyon DetaylarÄ±

### Ortam DeÄŸiÅŸkenleri (.env)

```bash
# MinIO Configuration
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_SECURE=false
MINIO_BUCKET_DOCS=raw-pdfs
MINIO_BUCKET_CHUNKS=chunks

# Milvus Configuration
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_COLLECTION=rag_chunks
MILVUS_INDEX_TYPE=IVF_FLAT
MILVUS_METRIC_TYPE=IP
MILVUS_NLIST=128

# Embedding Configuration
EMBEDDING_MODEL=BAAI/bge-m3
EMBEDDING_BATCH_SIZE=32
EMBEDDING_DEVICE=cuda  # veya cpu
RERANKER_MODEL=BAAI/bge-reranker-v2-m3

# LLM Configuration
LLM_PROVIDER=openai  # openai veya ollama
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b-instruct

# Chunking Configuration
CHUNK_SIZE=512
CHUNK_OVERLAP=50
CHUNK_METHOD=token  # token veya character

# API Configuration
API_HOST=0.0.0.0
API_PORT=8080
API_WORKERS=4
CORS_ORIGINS=["http://localhost:3000"]

# Logging
LOG_LEVEL=INFO
LOG_FILE=/app/logs/app.log
```

### Milvus Collection Schema

```python
{
  "collection_name": "rag_chunks",
  "fields": [
    {
      "name": "id",
      "type": "VARCHAR",
      "max_length": 100,
      "is_primary": True
    },
    {
      "name": "embedding",
      "type": "FLOAT_VECTOR",
      "dim": 1024
    },
    {
      "name": "document_id",
      "type": "VARCHAR",
      "max_length": 100
    },
    {
      "name": "chunk_index",
      "type": "INT64"
    },
    {
      "name": "page_number",
      "type": "INT64"
    },
    {
      "name": "text_hash",
      "type": "VARCHAR",
      "max_length": 64
    },
    {
      "name": "created_at",
      "type": "INT64"
    }
  ],
  "index_params": {
    "metric_type": "IP",
    "index_type": "IVF_FLAT",
    "params": {"nlist": 128}
  }
}
```

## ğŸ“Š Pipeline DetaylarÄ±

### 1. PDF Parsing (parse.py)

```python
Fonksiyonlar:
- extract_text_from_pdf(file_path) -> List[PageContent]
  - PyMuPDF kullanarak metin Ã§Ä±karma
  - Her sayfa iÃ§in metadata oluÅŸturma
  - GÃ¶rÃ¼ntÃ¼ ve tablo tespiti
  
- extract_metadata(file_path) -> DocumentMetadata
  - BaÅŸlÄ±k, yazar, oluÅŸturma tarihi
  - Sayfa sayÄ±sÄ±, dosya boyutu
  - Dil tespiti
```

### 2. Text Chunking (chunk.py)

```python
Stratejiler:
1. Token-based chunking
   - tiktoken encoder kullanÄ±mÄ±
   - Overlap ile context korunmasÄ±
   - CÃ¼mle sÄ±nÄ±rlarÄ±na dikkat

2. Semantic chunking
   - Paragraf ve bÃ¶lÃ¼m tespiti
   - Anlamsal bÃ¼tÃ¼nlÃ¼k korunmasÄ±
   
3. Hybrid approach
   - Token limiti + semantic boundaries
   - Optimal chunk boyutu
```

### 3. Embedding Generation (embed.py)

```python
Ã–zellikler:
- Batch processing (32 chunks/batch)
- GPU acceleration (if available)
- Normalization
- Dimension reduction (opsiyonel)
- Cache mekanizmasÄ±
```

### 4. Vector Indexing (index.py)

```python
Ä°ndeks TÃ¼rleri:
1. IVF_FLAT
   - Orta Ã¶lÃ§ekli veri iÃ§in optimal
   - nlist=128 clusters
   
2. HNSW
   - BÃ¼yÃ¼k Ã¶lÃ§ekli veri iÃ§in
   - M=16, ef_construction=200
   
3. AUTOINDEX
   - Otomatik optimizasyon
```

### 5. Retrieval & Reranking (retrieve.py)

```python
Arama Stratejisi:
1. Initial retrieval
   - Top-K=10 semantic search
   - Cosine similarity
   
2. Reranking
   - Cross-encoder model
   - Score normalization
   - Top-5 selection
   
3. Diversity
   - MMR (Maximal Marginal Relevance)
   - Duplicate removal
```

### 6. Response Generation (generate.py)

```python
Prompt Engineering:
- System prompt: RAG context instructions
- Context formatting: Numbered sources
- Citation requirements
- Hallucination prevention
- Token management
```

## ğŸ§ª Test SenaryolarÄ±

### Unit Tests

```bash
# TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
pytest tests/

# Belirli bir modÃ¼lÃ¼ test et
pytest tests/test_chunk.py -v

# Coverage raporu
pytest --cov=app tests/
```

### Integration Tests

```python
1. End-to-end PDF processing
2. Vector search accuracy
3. API response validation
4. Concurrent request handling
5. Error recovery
```

### Performance Tests

```bash
# Locust ile yÃ¼k testi
locust -f tests/locustfile.py \
  --host=http://localhost:8080 \
  --users=100 \
  --spawn-rate=10
```

## ğŸ“ˆ Monitoring & Observability

### Metrics

```yaml
Prometheus Metrics:
- pdf_processing_duration_seconds
- embedding_generation_duration_seconds
- query_latency_seconds
- milvus_search_duration_seconds
- llm_generation_tokens_total
```

### Logging

```python
Structured Logging:
{
  "timestamp": "2024-01-01T12:00:00Z",
  "level": "INFO",
  "service": "ingest",
  "document_id": "doc_123",
  "stage": "chunking",
  "chunks_created": 42,
  "duration_ms": 1234
}
```

### Dashboards

- **Grafana Dashboard**: System metrics, API latency, throughput
- **Milvus Attu**: Vector database management
- **MinIO Console**: Object storage monitoring

## ğŸš¦ Production Deployment

### Scaling Considerations

```yaml
1. Horizontal Scaling:
   - FastAPI workers: 4-8 per container
   - Load balancer: Nginx/Traefik
   - Session affinity for WebSocket

2. Database Scaling:
   - Milvus cluster mode
   - Read replicas
   - Partition by date/source

3. Caching:
   - Redis for embedding cache
   - CDN for static assets
   - Query result caching
```

### Security Best Practices

```yaml
1. Authentication:
   - JWT tokens
   - API key management
   - Rate limiting

2. Data Security:
   - Encryption at rest (MinIO)
   - TLS for all connections
   - Secrets management (Vault)

3. Input Validation:
   - File type verification
   - Size limits
   - Content scanning
```

### Backup & Recovery

```bash
# Milvus backup
docker exec milvus /milvus/bin/save --collection rag_chunks

# MinIO sync
mc mirror minio/raw-pdfs s3/backup-bucket/

# Database export
docker exec milvus /milvus/bin/export --path /backup/
```

## ğŸ” Troubleshooting

### Common Issues

1. **Milvus Connection Error**
   ```bash
   # Check Milvus status
   docker-compose logs milvus
   # Restart service
   docker-compose restart milvus
   ```

2. **Embedding Model Loading**
   ```bash
   # Clear model cache
   rm -rf ~/.cache/huggingface/
   # Re-download model
   python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('BAAI/bge-m3')"
   ```

3. **Memory Issues**
   ```yaml
   # docker-compose.yml iÃ§inde memory limits
   services:
     app:
       mem_limit: 4g
       memswap_limit: 4g
   ```

## ğŸ¯ KullanÄ±m Ã–rnekleri

### Ã–rnek 1: Teknik DokÃ¼man Ä°ndeksleme

```python
import requests

# PDF yÃ¼kleme
with open("technical_manual.pdf", "rb") as f:
    response = requests.post(
        "http://localhost:8080/ingest",
        files={"file": f},
        data={
            "metadata": json.dumps({
                "category": "technical",
                "version": "2.0",
                "language": "tr"
            })
        }
    )

# Soru sorma
query = {
    "question": "Sistemin kurulum gereksinimleri nelerdir?",
    "filters": {"category": "technical"},
    "top_k": 3
}

response = requests.post(
    "http://localhost:8080/query",
    json=query
)
```

### Ã–rnek 2: Batch Processing

```python
import asyncio
import aiohttp

async def process_pdf(session, file_path):
    async with session.post(
        "http://localhost:8080/ingest",
        data={"file": open(file_path, "rb")}
    ) as response:
        return await response.json()

async def batch_ingest(pdf_files):
    async with aiohttp.ClientSession() as session:
        tasks = [process_pdf(session, f) for f in pdf_files]
        return await asyncio.gather(*tasks)

# Ã‡oklu PDF iÅŸleme
pdf_list = ["doc1.pdf", "doc2.pdf", "doc3.pdf"]
results = asyncio.run(batch_ingest(pdf_list))
```

### Ã–rnek 3: WebSocket ile GerÃ§ek ZamanlÄ± Ä°zleme

```javascript
// Frontend JavaScript
class RAGClient {
    constructor(apiUrl) {
        this.apiUrl = apiUrl;
        this.ws = null;
    }
    
    connectWebSocket() {
        this.ws = new WebSocket(`${this.apiUrl}/ws`);
        
        this.ws.onopen = () => {
            console.log("WebSocket connected");
        };
        
        this.ws.onmessage = (event) => {
            const data = JSON.parse(event.data);
            this.handleProgress(data);
        };
    }
    
    handleProgress(data) {
        switch(data.type) {
            case 'parsing':
                console.log(`Parsing: ${data.progress}%`);
                break;
            case 'chunking':
                console.log(`Chunking: ${data.chunks_created} chunks`);
                break;
            case 'embedding':
                console.log(`Embedding: ${data.progress}%`);
                break;
            case 'complete':
                console.log(`Processing complete: ${data.document_id}`);
                break;
        }
    }
    
    async uploadPDF(file) {
        const formData = new FormData();
        formData.append('file', file);
        
        const response = await fetch(`${this.apiUrl}/ingest`, {
            method: 'POST',
            body: formData
        });
        
        return response.json();
    }
}
```

## ğŸ› ï¸ Development Workflow

### Local Development

```bash
# Virtual environment oluÅŸturma
python -m venv venv
source venv/bin/activate  # Linux/Mac
# veya
venv\Scripts\activate  # Windows

# Dependencies kurulumu
pip install -r requirements.txt

# Development server
uvicorn app.server:app --reload --port 8080

# Code formatting
black app/
isort app/

# Type checking
mypy app/

# Linting
flake8 app/
```

### Git Workflow

```bash
# Feature branch
git checkout -b feature/new-chunking-strategy

# Commit convention
git commit -m "feat: add semantic chunking support"
git commit -m "fix: resolve embedding dimension mismatch"
git commit -m "docs: update API documentation"

# Pull request
git push origin feature/new-chunking-strategy
```

## ğŸ“š Kaynaklar

### DokÃ¼mantasyon
- [Milvus Docs](https://milvus.io/docs)
- [MinIO Docs](https://docs.min.io)
- [FastAPI Docs](https://fastapi.tiangolo.com)
- [BGE Models](https://huggingface.co/BAAI)

### Papers & Research
- "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" (Lewis et al., 2020)
- "Dense Passage Retrieval for Open-Domain Question Answering" (Karpukhin et al., 2020)

### Community
- [GitHub Issues](https://github.com/yourusername/onedocs-rag/issues)
- [Discord Server](#)

## ğŸ“„ Lisans

MIT License - Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

---

**Version:** 1.0.0  
**Last Updated:** 2024-12-04  
**Maintainer:** AI Team