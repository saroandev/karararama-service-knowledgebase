# OneDocs RAG Sistemi - Veri AkÄ±ÅŸ Mimarisi

## ğŸ¯ Genel BakÄ±ÅŸ

OneDocs RAG sistemi, PDF dokÃ¼manlarÄ±nÄ± iÅŸleyen, vektÃ¶r veritabanÄ±nda saklayan ve kullanÄ±cÄ± sorularÄ±na kaynak gÃ¶stererek cevap veren bir Retrieval-Augmented Generation (RAG) uygulamasÄ±dÄ±r.

## ğŸ“Š Sistem BileÅŸenleri

### 1. Frontend KatmanÄ±
- **Streamlit Web UygulamasÄ±** (`streamlit_app.py`)
  - Port: 8501
  - KullanÄ±cÄ± arayÃ¼zÃ¼ ve chat interface
  - PDF yÃ¼kleme ve soru-cevap iÅŸlemleri

### 2. Backend API KatmanÄ±
- **Production Server** (`production_server.py`)
  - Port: 8080
  - FastAPI tabanlÄ± REST API
  - KalÄ±cÄ± veri depolama ile optimize edilmiÅŸ

- **Development Server** (`app/server.py`)
  - Port: 8080
  - WebSocket destekli geliÅŸmiÅŸ Ã¶zellikler
  - KapsamlÄ± API endpoint'leri

### 3. Veri Depolama KatmanÄ±
- **Milvus Vector Database**
  - Port: 19530 (gRPC)
  - VektÃ¶r embedding'lerini saklar
  - Collection: `rag_production_v1`

- **MinIO Object Storage**
  - Port: 9000 (API), 9001 (Console)
  - Ham dokÃ¼man ve metin verilerini saklar

- **ETCD**
  - Port: 2379
  - Metadata yÃ¶netimi

## ğŸ”„ Veri AkÄ±ÅŸ DiyagramÄ±

```mermaid
graph TB
    subgraph "1. KullanÄ±cÄ± EtkileÅŸimi"
        A[KullanÄ±cÄ±] -->|PDF YÃ¼kler| B[Streamlit UI<br/>:8501]
        A -->|Soru Sorar| B
    end
    
    subgraph "2. API Gateway"
        B -->|POST /ingest| C[FastAPI Server<br/>:8080]
        B -->|POST /query| C
    end
    
    subgraph "3. DokÃ¼man Ä°ÅŸleme Pipeline"
        C -->|PDF Parse| D[PDFParser<br/>app/parse.py]
        D -->|Text Extraction| E[Text Chunks<br/>app/chunk.py]
        E -->|Generate Embeddings| F[OpenAI API<br/>text-embedding-3-small]
    end
    
    subgraph "4. Veri Depolama"
        F -->|Store Vectors| G[Milvus DB<br/>:19530]
        D -->|Store Raw Text| H[MinIO<br/>:9000]
        G -->|Metadata| I[ETCD<br/>:2379]
    end
    
    subgraph "5. Sorgulama Pipeline"
        C -->|Query Embedding| J[OpenAI Embeddings]
        J -->|Vector Search| G
        G -->|Top-K Results| K[Retriever<br/>app/retrieve.py]
        K -->|Context Assembly| L[LLM Generator<br/>app/generate.py]
    end
    
    subgraph "6. Cevap Ãœretimi"
        L -->|GPT-4o-mini| M[OpenAI API]
        M -->|Generated Answer| C
        C -->|JSON Response| B
        B -->|Display Result| A
    end
```

## ğŸ“¥ DokÃ¼man YÃ¼kleme AkÄ±ÅŸÄ± (Ingestion Flow)

### AdÄ±m 1: PDF YÃ¼kleme
```
KullanÄ±cÄ± â†’ Streamlit UI â†’ Multipart Form Data â†’ FastAPI /ingest endpoint
```

### AdÄ±m 2: PDF Ä°ÅŸleme
```python
# production_server.py:100-115
1. PDF validasyonu (sadece .pdf uzantÄ±lÄ± dosyalar)
2. MD5 hash hesaplama (duplicate kontrolÃ¼ iÃ§in)
3. Document ID oluÅŸturma: doc_{hash[:16]}
```

### AdÄ±m 3: Text Extraction
```python
# app/parse.py â†’ PDFParser.extract_text_from_pdf()
1. PyMuPDF ile PDF parsing
2. Her sayfa iÃ§in text ve metadata Ã§Ä±karma
3. PageContent objeleri oluÅŸturma
```

### AdÄ±m 4: Text Chunking
```python
# production_server.py:131-151
1. Her sayfa metni iÃ§in chunk oluÅŸturma
2. 100 karakterden kÄ±sa sayfalar atlanÄ±r
3. Chunk ID formatÄ±: chunk_{doc_id}_{page_index}_{hash}
```

### AdÄ±m 5: Embedding Generation
```python
# production_server.py:178-214
1. OpenAI API Ã§aÄŸrÄ±sÄ± (text-embedding-3-small)
2. Her chunk iÃ§in 1536 boyutlu vektÃ¶r
3. Batch processing (5 chunk'ta bir log)
```

### AdÄ±m 6: Milvus Storage
```python
# production_server.py:216-226
1. VektÃ¶rler ve metadata Milvus'a insert edilir
2. Collection: rag_production_v1
3. Alanlar: chunk_id, document_id, document_title, text, embedding, page_num, chunk_index, created_at, file_hash
```

## ğŸ” Sorgulama AkÄ±ÅŸÄ± (Query Flow)

### AdÄ±m 1: KullanÄ±cÄ± Sorusu
```
KullanÄ±cÄ± â†’ Streamlit Chat Input â†’ POST /query â†’ FastAPI
```

### AdÄ±m 2: Query Embedding
```python
# production_server.py:273-278
1. Soru metni OpenAI embeddings API'ye gÃ¶nderilir
2. 1536 boyutlu query vektÃ¶rÃ¼ oluÅŸturulur
```

### AdÄ±m 3: Vector Search
```python
# production_server.py:285-293
1. Milvus'ta cosine similarity search
2. Top-K (varsayÄ±lan 3) en benzer chunk bulunur
3. Optional: document_id filtresi uygulanabilir
```

### AdÄ±m 4: Context Assembly
```python
# production_server.py:303-325
1. Her sonuÃ§ iÃ§in score, document info, text alÄ±nÄ±r
2. Context formatÄ±: [Kaynak N - Sayfa X]: {text}
3. Sources array hazÄ±rlanÄ±r (rank, score, preview)
```

### AdÄ±m 5: LLM Generation
```python
# production_server.py:330-351
1. System prompt: RAG asistanÄ± rolÃ¼
2. Context ve soru GPT-4o-mini'ye gÃ¶nderilir
3. Max 500 token cevap Ã¼retilir
4. Kaynak referanslarÄ± eklenir
```

### AdÄ±m 6: Response
```json
{
  "answer": "Cevap metni [Kaynak 1]...",
  "sources": [
    {
      "rank": 1,
      "score": 0.95,
      "document_title": "DokÃ¼man AdÄ±",
      "page_number": 5,
      "text_preview": "Ä°lgili metin...",
      "created_at": "2024-01-01T10:00:00"
    }
  ],
  "processing_time": 1.5,
  "model_used": "gpt-4o-mini"
}
```

## ğŸ”§ Teknik Detaylar

### Embedding BoyutlarÄ±
- OpenAI text-embedding-3-small: 1536 boyut
- Local models (multilingual-e5-small): deÄŸiÅŸken boyut

### Token Limitleri
- Chunk boyutu: 512 token
- Overlap: 50 token
- LLM response: max 500 token

### VeritabanÄ± ÅemasÄ±

#### Milvus Collection: rag_production_v1
```python
Fields:
- id: int64 (primary key, auto-generated)
- chunk_id: varchar(255)
- document_id: varchar(255)
- document_title: varchar(1024)
- text: varchar(65535)
- embedding: float_vector(1536)
- page_num: int64
- chunk_index: int64
- created_at: varchar(50)
- file_hash: varchar(64)

Index:
- Type: IVF_FLAT
- Metric: COSINE
- nlist: 128
```

### API Endpoint'leri

#### Production Server
- `GET /health` - Sistem saÄŸlÄ±k kontrolÃ¼
- `POST /ingest` - PDF dokÃ¼man yÃ¼kleme
- `POST /query` - Soru sorma
- `GET /documents` - DokÃ¼man listesi
- `DELETE /documents/{document_id}` - DokÃ¼man silme

### Docker Servisleri
```yaml
Services:
- app (FastAPI): Port 8080
- streamlit: Port 8501
- milvus: Port 19530, 9091
- minio: Port 9000, 9001
- etcd: Port 2379
- attu (Milvus GUI): Port 8000
```

## ğŸš€ Performans OptimizasyonlarÄ±

### 1. Batch Processing
- Embedding generation batch halinde yapÄ±lÄ±r
- Her 5 chunk'ta bir progress log

### 2. Connection Pooling
- Milvus connection reuse
- OpenAI client singleton pattern

### 3. Caching
- Document hash ile duplicate kontrolÃ¼
- Existing document check before insert

### 4. Async Operations
- FastAPI async endpoints
- Background task support

## ğŸ“ˆ Veri AkÄ±ÅŸ Ã–zeti

1. **GiriÅŸ NoktasÄ±**: KullanÄ±cÄ± Streamlit UI Ã¼zerinden PDF yÃ¼kler veya soru sorar
2. **API Ä°letiÅŸimi**: Streamlit, FastAPI backend'e HTTP request gÃ¶nderir
3. **PDF Ä°ÅŸleme**: PyMuPDF â†’ Chunking â†’ OpenAI Embeddings
4. **Veri Saklama**: VektÃ¶rler Milvus'a, metinler MinIO'ya
5. **Sorgulama**: Query embedding â†’ Vector search â†’ Context assembly
6. **Cevap Ãœretimi**: GPT-4o-mini ile kaynak referanslÄ± cevap
7. **SonuÃ§**: JSON response â†’ Streamlit UI â†’ KullanÄ±cÄ±ya gÃ¶sterim

## ğŸ” GÃ¼venlik ve Yetkilendirme

### Mevcut Durum
- CORS: TÃ¼m origin'lere aÃ§Ä±k (*)
- Authentication: YOK
- Rate limiting: YOK
- Input validation: Sadece dosya tipi kontrolÃ¼

### Production Ä°Ã§in Ã–neriler
- JWT tabanlÄ± authentication
- API key management
- Rate limiting (per IP/user)
- Input sanitization
- SSL/TLS configuration

## ğŸ“Š Monitoring ve Logging

### Log Seviyeleri
- INFO: Normal iÅŸlemler
- ERROR: Hata durumlarÄ±
- DEBUG: DetaylÄ± debugging (development)

### Metrikler
- Processing time tracking
- Entity count monitoring
- Query performance metrics
- Document ingestion stats

## ğŸ¯ KullanÄ±m SenaryolarÄ±

1. **DokÃ¼man YÃ¼kleme**
   - KullanÄ±cÄ± PDF yÃ¼kler
   - Sistem otomatik olarak iÅŸler ve indexler
   - Duplicate kontrolÃ¼ yapÄ±lÄ±r

2. **Soru-Cevap**
   - KullanÄ±cÄ± soru sorar
   - Sistem en ilgili chunk'larÄ± bulur
   - Kaynak gÃ¶stererek cevap Ã¼retir

3. **DokÃ¼man YÃ¶netimi**
   - YÃ¼klenen dokÃ¼manlarÄ± listeleme
   - Belirli bir dokÃ¼manÄ± silme
   - DokÃ¼man bazlÄ± filtreleme

## ğŸ“ Notlar

- Production server (`production_server.py`) daha basit ve optimize edilmiÅŸ
- Development server (`app/server.py`) daha fazla Ã¶zellik iÃ§erir (WebSocket, background tasks)
- TÃ¼m iÅŸlemler async/await pattern kullanÄ±r
- Docker-first deployment stratejisi uygulanmÄ±ÅŸ